[INFO 06:39:40] pymarl Running command 'my_main'
[INFO 06:39:40] pymarl Started run with ID "15"
[DEBUG 06:39:40] pymarl Starting Heartbeat
[DEBUG 06:39:40] my_main Started
[INFO 06:39:40] root Using run module: run
/home/qh/yuanma/epymarl/src/envs/gymma.py:16: UserWarning: PettingZoo is not installed, so these environments will not be available! To install, run `pip install pettingzoo`
  warnings.warn(
/home/qh/yuanma/epymarl/src/envs/gymma.py:23: UserWarning: VMAS is not installed, so these environments will not be available! To install, run `pip install 'vmas[gymnasium]'`
  warnings.warn(
[INFO 06:39:41] root Imported run function from run.py
[INFO 06:39:41] my_main Experiment Parameters:
[INFO 06:39:41] my_main 

{   'action_selector': 'epsilon_greedy',
    'add_value_last_step': True,
    'adj_threshold': 0.5,
    'agent': 'rnn',
    'agent_output_type': 'q',
    'batch_size': 32,
    'batch_size_run': 1,
    'buffer_cpu_only': True,
    'buffer_size': 5000,
    'checkpoint_path': '',
    'common_reward': True,
    'concate_gcn': True,
    'concate_mlp': False,
    'concate_mlp_dim': 10,
    'dicg_emb_hid': 128,
    'double_q': True,
    'env': 'sc2',
    'env_args': {   'continuing_episode': False,
                    'debug': False,
                    'difficulty': '7',
                    'game_version': None,
                    'heuristic_ai': False,
                    'heuristic_rest': False,
                    'map_name': '3m',
                    'move_amount': 2,
                    'obs_all_health': True,
                    'obs_instead_of_state': False,
                    'obs_last_action': False,
                    'obs_own_health': True,
                    'obs_pathing_grid': False,
                    'obs_terrain_height': False,
                    'obs_timestep_number': False,
                    'replay_dir': '',
                    'replay_prefix': '',
                    'reward_death_value': 10,
                    'reward_defeat': 0,
                    'reward_negative_scale': 0.5,
                    'reward_only_positive': True,
                    'reward_scale': True,
                    'reward_scale_rate': 20,
                    'reward_sparse': False,
                    'reward_win': 200,
                    'seed': 778633855,
                    'state_last_action': False,
                    'state_timestep_number': False,
                    'step_mul': 8},
    'epsilon_anneal_time': 50000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': False,
    'evaluation_epsilon': 0.0,
    'gamma': 0.99,
    'gcn_message_dim': 0.3,
    'grad_norm_clip': 10,
    'group_loss_weight': 0.01,
    'group_num': 2,
    'hidden_dim': 64,
    'hypergroup': None,
    'hypernet_embed': 64,
    'hypernet_layers': 2,
    'is_masssge': True,
    'is_sparse': True,
    'is_train_groupnizer': True,
    'label': 'default_label',
    'learner': 'gacg_learner',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.0005,
    'mac': 'gacg_mac',
    'mixer': 'qmix',
    'mixing_embed_dim': 32,
    'name': 'GACG',
    'number_gcn_layers': 2,
    'obs_agent_id': True,
    'obs_group_trunk_size': 10,
    'obs_last_action': True,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'render': False,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'runner': 'episode',
    'runner_log_interval': 10000,
    'save_model': False,
    'save_model_interval': 2000000,
    'save_replay': False,
    'seed': 778633855,
    'standardise_returns': False,
    'standardise_rewards': True,
    't_max': 2050000,
    'target_update_interval': 200,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 100,
    'train_graph': False,
    'use_cuda': True,
    'use_rnn': True,
    'use_tensorboard': False,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

gcn_message_dim 9
[INFO 06:39:41] my_main Beginning training for 2050000 timesteps
[INFO 06:39:41] absl Launching SC2: /home/qh/StarCraftII/Versions/Base69232/SC2_x64 -listen 127.0.0.1 -port 42609 -dataDir /home/qh/StarCraftII/ -tempDir /tmp/sc-923cxx42/
[INFO 06:39:41] absl Connecting to: ws://127.0.0.1:42609/sc2api, attempt: 0, running: True
Version: B69232 (SC2.4.6-Publish)
Build: Oct 23 2018 01:43:04
Command Line: '"/home/qh/StarCraftII/Versions/Base69232/SC2_x64" -listen 127.0.0.1 -port 42609 -dataDir /home/qh/StarCraftII/ -tempDir /tmp/sc-923cxx42/'
Starting up...
Startup Phase 1 complete
[INFO 06:39:43] absl Connecting to: ws://127.0.0.1:42609/sc2api, attempt: 1, running: True
Startup Phase 2 complete
Creating stub renderer...
Listening on: 127.0.0.1:42609
Startup Phase 3 complete. Ready for commands.
[INFO 06:39:44] absl Connecting to: ws://127.0.0.1:42609/sc2api, attempt: 2, running: True
Requesting to join a single player game
Configuring interface options
Configure: raw interface enabled
Configure: feature layer interface disabled
Configure: score interface disabled
Configure: render interface disabled
Entering load game phase.
Launching next game.
Next launch phase started: 2
Next launch phase started: 3
Next launch phase started: 4
Next launch phase started: 5
Next launch phase started: 6
Next launch phase started: 7
Next launch phase started: 8
Game has started.
Sending ResponseJoinGame
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:93: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  target["filled"][slices] = 1
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:105: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  self._check_safe_view(v, target[k][_slices])
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:106: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  target[k][_slices] = v.view_as(target[k][_slices])
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:110: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  v = target[k][_slices]
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:113: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  target[new_k][_slices] = v.view_as(target[new_k][_slices])
[INFO 06:39:44] my_main t_env: 24 / 2050000
[INFO 06:39:44] my_main Estimated time left: 9 minutes, 34 seconds. Time passed: 2 seconds
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:152: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  new_data.transition_data[k] = v[item]
/home/qh/yuanma/epymarl/src/learners/gacg_learner.py:262: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
  numerator += (1 / (dist.numel()+ eps)) * float(dist.sum())
[INFO 06:41:43] my_main Updated target network
[INFO 06:43:24] my_main Recent Stats | t_env:      10023 | Episode:      379
Gdistance_mean:            2.6907	battle_won_mean:           0.0000	dead_allies_mean:          3.0000	dead_enemies_mean:         0.0000
ep_length_mean:           24.0000	epsilon:                   1.0000	grad_norm:                 0.7286	loss:                      0.0028
q_taken_mean:              0.0245	return_mean:               1.9726	return_std:                0.0000	target_mean:               0.0634
td_error_abs:              0.1211	test_battle_won_mean:      0.0000	test_dead_allies_mean:     2.9900	test_dead_enemies_mean:    0.0000
test_ep_length_mean:      22.6800	test_return_mean:          0.0329	test_return_std:           0.0986	
[INFO 06:43:25] my_main t_env: 10052 / 2050000
[INFO 06:43:25] my_main Estimated time left: 12 hours, 28 minutes, 33 seconds. Time passed: 3 minutes, 43 seconds
[INFO 06:44:22] my_main Updated target network
[INFO 06:46:08] my_main Updated target network
