[INFO 21:03:52] pymarl Running command 'my_main'
[INFO 21:03:52] pymarl Started run with ID "9"
[DEBUG 21:03:52] pymarl Starting Heartbeat
[DEBUG 21:03:52] my_main Started
[INFO 21:03:52] root Using run module: run
/home/qh/yuanma/epymarl/src/envs/gymma.py:16: UserWarning: PettingZoo is not installed, so these environments will not be available! To install, run `pip install pettingzoo`
  warnings.warn(
/home/qh/yuanma/epymarl/src/envs/gymma.py:23: UserWarning: VMAS is not installed, so these environments will not be available! To install, run `pip install 'vmas[gymnasium]'`
  warnings.warn(
[INFO 21:03:53] root Imported run function from run.py
[INFO 21:03:53] my_main Experiment Parameters:
[INFO 21:03:53] my_main 

{   'action_selector': 'epsilon_greedy',
    'add_value_last_step': True,
    'agent': 'rnn',
    'agent_output_type': 'q',
    'batch_size': 32,
    'batch_size_run': 1,
    'buffer_cpu_only': True,
    'buffer_size': 5000,
    'checkpoint_path': '',
    'common_reward': True,
    'concate_gcn': True,
    'concate_mlp': True,
    'concate_mlp_dim': 10,
    'dicg_emb_hid': 128,
    'double_q': True,
    'env': 'sc2',
    'env_args': {   'continuing_episode': False,
                    'debug': False,
                    'difficulty': '7',
                    'game_version': None,
                    'heuristic_ai': False,
                    'heuristic_rest': False,
                    'map_name': '3m',
                    'move_amount': 2,
                    'obs_all_health': True,
                    'obs_instead_of_state': False,
                    'obs_last_action': False,
                    'obs_own_health': True,
                    'obs_pathing_grid': False,
                    'obs_terrain_height': False,
                    'obs_timestep_number': False,
                    'replay_dir': '',
                    'replay_prefix': '',
                    'reward_death_value': 10,
                    'reward_defeat': 0,
                    'reward_negative_scale': 0.5,
                    'reward_only_positive': True,
                    'reward_scale': True,
                    'reward_scale_rate': 20,
                    'reward_sparse': False,
                    'reward_win': 200,
                    'seed': 508612374,
                    'state_last_action': False,
                    'state_timestep_number': False,
                    'step_mul': 8},
    'epsilon_anneal_time': 50000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': False,
    'evaluation_epsilon': 0.0,
    'gamma': 0.99,
    'gcn_message_dim': 10,
    'grad_norm_clip': 10,
    'graph_emb_hid': 128,
    'graph_loss_weight': 1,
    'gtsmodel': {   'cl_decay_steps': 2000,
                    'dim_fc': 383552,
                    'filter_type': 'dual_random_walk',
                    'horizon': 12,
                    'input_dim': 2,
                    'l1_decay': 0,
                    'max_diffusion_step': 3,
                    'num_nodes': 207,
                    'num_rnn_layers': 1,
                    'output_dim': 1,
                    'rnn_units': 64,
                    'seq_len': 12,
                    'use_curriculum_learning': True},
    'hidden_dim': 64,
    'hypergroup': None,
    'hypernet_embed': 64,
    'hypernet_layers': 2,
    'label': 'default_label',
    'learner': 'LTSCG_learner',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.0005,
    'mac': 'Ltscg_mac',
    'mixer': 'qmix',
    'mixing_embed_dim': 32,
    'mlp_emb_hid': 64,
    'mlp_out': 32,
    'name': 'dicg',
    'number_gcn_layers': 2,
    'obs_agent_id': True,
    'obs_last_action': True,
    'obs_shape': 256,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'render': False,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'runner': 'episode',
    'runner_log_interval': 10000,
    'save_model': False,
    'save_model_interval': 50000,
    'save_replay': False,
    'seed': 508612374,
    'standardise_returns': False,
    'standardise_rewards': False,
    't_max': 2050000,
    'target_update_interval': 200,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 100,
    'train_graph': True,
    'use_cuda': True,
    'use_rnn': True,
    'use_tensorboard': False,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

[INFO 21:03:54] my_main Beginning training for 2050000 timesteps
[INFO 21:03:54] absl Launching SC2: /home/qh/StarCraftII/Versions/Base69232/SC2_x64 -listen 127.0.0.1 -port 37189 -dataDir /home/qh/StarCraftII/ -tempDir /tmp/sc-mc1wpuqw/
[INFO 21:03:54] absl Connecting to: ws://127.0.0.1:37189/sc2api, attempt: 0, running: True
Version: B69232 (SC2.4.6-Publish)
Build: Oct 23 2018 01:43:04
Command Line: '"/home/qh/StarCraftII/Versions/Base69232/SC2_x64" -listen 127.0.0.1 -port 37189 -dataDir /home/qh/StarCraftII/ -tempDir /tmp/sc-mc1wpuqw/'
Starting up...
Startup Phase 1 complete
[INFO 21:03:55] absl Connecting to: ws://127.0.0.1:37189/sc2api, attempt: 1, running: True
Startup Phase 2 complete
Creating stub renderer...
Listening on: 127.0.0.1:37189
Startup Phase 3 complete. Ready for commands.
[INFO 21:03:56] absl Connecting to: ws://127.0.0.1:37189/sc2api, attempt: 2, running: True
Requesting to join a single player game
Configuring interface options
Configure: raw interface enabled
Configure: feature layer interface disabled
Configure: score interface disabled
Configure: render interface disabled
Entering load game phase.
Launching next game.
Next launch phase started: 2
Next launch phase started: 3
Next launch phase started: 4
Next launch phase started: 5
Next launch phase started: 6
Next launch phase started: 7
Next launch phase started: 8
Game has started.
Sending ResponseJoinGame
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:93: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  target["filled"][slices] = 1
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:105: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  self._check_safe_view(v, target[k][_slices])
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:106: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  target[k][_slices] = v.view_as(target[k][_slices])
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:110: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  v = target[k][_slices]
/home/qh/yuanma/epymarl/src/components/episode_buffer.py:113: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  target[new_k][_slices] = v.view_as(target[new_k][_slices])
[INFO 21:04:00] my_main t_env: 25 / 2050000
[INFO 21:04:00] my_main Estimated time left: 19 minutes, 27 seconds. Time passed: 5 seconds
